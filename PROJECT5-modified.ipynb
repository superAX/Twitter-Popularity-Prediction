{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as statsmodel\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE SOME USEFUL FUNCTIONS \n",
    "\n",
    "\n",
    "\n",
    "def load_json_obj(file_name):\n",
    "    tweets = []   # define a list to store json object\n",
    "    f = open(file_name, 'r', encoding = 'utf-8')\n",
    "    data_in_row = f.readline()    # read a row (json string)\n",
    "    while len(data_in_row)!=0:    # if this row is nor empty,begin the loop\n",
    "        tweet = json.loads(data_in_row)    # transfer json string to json object\n",
    "        tweets.append(tweet)    # store json object into the list\n",
    "        line = f.readline()     # read a row\n",
    "    f.close()\n",
    "    return tweets    \n",
    "\n",
    "\n",
    "\n",
    "def calc_statistics(file_name):\n",
    "    \n",
    "    # load the json object list\n",
    "    tweets = load_json_obj(file_name)\n",
    "    \n",
    "    # define lists to store information\n",
    "    num_tweets_list = []   # store the number of tweets (each tweet is represented by 1)\n",
    "    num_retweets_list = []  # store the number of retweets for each tweet\n",
    "    num_users_list = []   # store the number of users (each user is represented by 1)\n",
    "    num_followers_list = []   # store the number of followers for each user\n",
    "        \n",
    "    # use start time and end time to calculate of the number total hours\n",
    "    start_time = tweets[0]['citation_date']\n",
    "    end_time = tweets[-1]['citation_date']\n",
    "    num_hours = math.ceil((end_time - start_time)/3600)   # math,ceil(15.0)=15, math.ceil(15.2)=16\n",
    "    \n",
    "    # find the values in the lists\n",
    "    for tweet in tweets: \n",
    "        num_tweets_list.append(1)\n",
    "        num_retweets_list.append(tweet['metrics']['citations']['total'])\n",
    "        num_users_list.append(1) \n",
    "        num_followers_list.append(tweet['author']['followers'])   # the number of followers for the user\n",
    "        \n",
    "    # calculate statistics\n",
    "    num_tweets = len(num_tweets_list)\n",
    "    num_retweets = np.sum(num_retweets_list)\n",
    "    num_users = len(user_id_list)\n",
    "    num_followers = np.sum(num_followers_list)\n",
    "    avg_tweets_per_hour = num_tweets / num_hours\n",
    "    avg_followers_per_tweet = num_followers / num_tweets\n",
    "    avg_retweets_per_tweet = num_retweets / num_tweets\n",
    "    \n",
    "    print('For %s :' %flie_name)\n",
    "    print('Average number of tweets per hour is ',avg_tweets_per_hour)\n",
    "    print('Average number of followers of users posting the tweets per tweet is 'avg_followers_per_tweet)\n",
    "    print('Average number of retweets per tweet is 'avg_retweets_per_tweet)\n",
    "    return avg_tweets_per_hour, avg_followers_per_tweet, avg_retweets_per_tweet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_num_tweets_per_hour(flie_name, hashtag_name):\n",
    "    \n",
    "    # load the json object list\n",
    "    tweets = load_json_obj(file_name)\n",
    "    \n",
    "    # use start time and end time to calculate of the number total hours\n",
    "    start_time = tweets[0]['citation_date']\n",
    "    end_time = tweets[-1]['citation_date']\n",
    "    num_hours = math.ceil((end_time - start_time)/3600)   # math,ceil(15.0)=15, math.ceil(15.2)=16\n",
    "    \n",
    "    # calculate the number of tweets in each hour\n",
    "    num_tweets_in_hours = np.zeros(num_hours).tolist()\n",
    "    for i in range(len(tweets)):\n",
    "        hour_idx = int((tweets[i]['citation_date'] - start_time)/3600)   # in which hour\n",
    "        num_tweets_in_hours[hour_idx] += 1\n",
    "    \n",
    "    # plot the figure\n",
    "    plt.figure()\n",
    "    plt.bar(range(num_hours), num_tweets_in_hours, width=1)\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Number of tweets')\n",
    "    plt.title(('Number of tweets in hour for ' + hashtag_name))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\"\"\"    \n",
    "def extract_five_features(file_name):\n",
    "    \n",
    "    # load the json object list\n",
    "    tweets = load_json_obj(file_name)\n",
    "    \n",
    "    # define a dictionary to store feature values for each hour\n",
    "    hourly_features = {}  \n",
    "    \n",
    "    for tweet in tweets:\n",
    "        # deal with time format\n",
    "        tweet_time_UNIX = tweet['citation_date'] \n",
    "        pst_tz = pytz.timezone('America/Los_Angeles')\n",
    "        tweet_time = datetime.datetime.fromtimestamp(tweet_time_UNIX,pst_tz) \n",
    "        tweet_hour_time = datetime.datetime(tweet_time.year, tweet_time.month, tweet_time.day, tweet_time.hour, 0, 0)\n",
    "        tweet_hour_time = str(tweet_hour_time)\n",
    "        # calculate feature values    \n",
    "        if tweet_hour_time not in hourly_features: \n",
    "            hourly_features[tweet_hour_time] = {'num_tweets':0, 'num_retweets':0, 'num_followers':0, 'max_followers':0, 'hour':0}\n",
    "        hourly_features[tweet_hour_time]['num_tweets'] += 1\n",
    "        hourly_features[tweet_hour_time]['num_retweets'] += tweet['metrics']['citations']['total']\n",
    "        hourly_features[tweet_hour_time]['num_followers'] += tweet['author']['followers']\n",
    "        if tweet['author']['followers'] > hourly_features[tweet_hour_time]['max_followers']:\n",
    "            hourly_features[tweet_hour_time]['max_followers'] = tweet['author']['followers']\n",
    "        hourly_features[tweet_hour_time]['hour'] = tweet_time.hour\n",
    "                 \n",
    "    return hourly_features\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def extract_five_features(flie_name):\n",
    "    \n",
    "    # load the json object list\n",
    "    tweets = load_json_obj(file_name)\n",
    "    \n",
    "    # use start time and end time to calculate of the number total hours\n",
    "    start_time = tweets[0]['citation_date']\n",
    "    end_time = tweets[-1]['citation_date']\n",
    "    num_hours = math.ceil((end_time - start_time)/3600)   # math,ceil(15.0)=15, math.ceil(15.2)=16\n",
    "    \n",
    "    # define a np.array to store feature values\n",
    "    hourly_features = np.zeros([num_hours,5])\n",
    "    \n",
    "    # calculate the feature values in each hour\n",
    "    num_tweets_in_hours = np.zeros(num_hours).tolist()\n",
    "    for tweet in tweets:\n",
    "        hour_idx = int((tweet['citation_date'] - start_time)/3600)   # in which hour (in which index)\n",
    "        hourly_features[hour_idx][0] += 1  # total number of tweets\n",
    "        hourly_features[hour_idx][1] += tweet['metrics']['citations']['total']  # total number of retweets\n",
    "        hourly_features[hour_idx][2] += tweet['author']['followers']  # total number of followers\n",
    "        if tweet['author']['followers'] > hourly_features[hour_idx][3]:\n",
    "            hourly_features[hour_idx][3] += tweet['author']['followers']  # maximum followers\n",
    "        tweet_time_UNIX = tweet['citation_date'] \n",
    "        pst_tz = pytz.timezone('America/Los_Angeles')\n",
    "        tweet_time = datetime.datetime.fromtimestamp(tweet_time_UNIX,pst_tz) \n",
    "        hourly_features[hour_idx][4] = tweet_time.hour  # hour\n",
    "        \n",
    "    return hourly_features\n",
    "\n",
    "\n",
    "\n",
    "def extract_more_features(flie_name):\n",
    "    \n",
    "    # load the json object list\n",
    "    tweets = load_json_obj(file_name)\n",
    "    \n",
    "    # use start time and end time to calculate of the number total hours\n",
    "    start_time = tweets[0]['citation_date']\n",
    "    end_time = tweets[-1]['citation_date']\n",
    "    num_hours = math.ceil((end_time - start_time)/3600)   # math,ceil(15.0)=15, math.ceil(15.2)=16\n",
    "    \n",
    "    # define a np.array to store feature values\n",
    "    hourly_features = np.zeros([num_hours,14])\n",
    "    \n",
    "    # calculate the feature values in each hour\n",
    "    num_tweets_in_hours = np.zeros(num_hours).tolist()\n",
    "    for tweet in tweets:\n",
    "        hour_idx = int((tweet['citation_date'] - start_time)/3600)   # in which hour (in which index)\n",
    "        hourly_features[hour_idx][0] += 1  # total number of tweets\n",
    "        hourly_features[hour_idx][1] += tweet['metrics']['citations']['total']  # total number of retweets\n",
    "        hourly_features[hour_idx][2] += tweet['author']['followers']  # total number of followers\n",
    "        if tweet['author']['followers'] > hourly_features[hour_idx][3]:\n",
    "            hourly_features[hour_idx][3] += tweet['author']['followers']  # maximum followers\n",
    "        tweet_time_UNIX = tweet['citation_date'] \n",
    "        pst_tz = pytz.timezone('America/Los_Angeles')\n",
    "        tweet_time = datetime.datetime.fromtimestamp(tweet_time_UNIX,pst_tz) \n",
    "        hourly_features[hour_idx][4] = tweet_time.hour  # hour\n",
    "        \"\"\" #user_id needs to be defined\n",
    "        hourly_features[hour_idx][5] += tweet['metrics']['impressions']\n",
    "        hourly_features[hour_idx][6] += tweet['metrics']['momentum']\n",
    "        hourly_features[hour_idx][7] += tweet['tweet']['favorite_count']\n",
    "        hourly_features[hour_idx][8] += tweet['metrics']['ranking_score']\n",
    "        hourly_features[hour_idx][9] += tweet['metrics']['acceleration']\n",
    "        hourly_features[hour_idx][10] += tweet['metrics']['citations']['replies']\n",
    "        if tweet['tweet']['user']['id'] not in dict_unique_users[hour_num]:\n",
    "            dict_unique_users[hour_num].add(tweet['tweet']['user']['id'])\n",
    "            hourly_features[hour_idx][11] += 1\n",
    "        if tweet['author']['name'] not in dict_unique_authors[hour_num]:\n",
    "            dict_unique_authors[hour_num].add(tweet['author']['name'])\n",
    "            hourly_features[hour_idx][12] += 1\n",
    "        hourly_features[hour_idx][13] += len(tweet['tweet']['entities']['user_mentions'])\n",
    "        \"\"\"\n",
    "    return hourly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 1\n",
    "\n",
    "\n",
    "file_names = ['tweets_#gohawks.txt', 'tweets_#gopatriots.txt', 'tweets_#nfl.txt',\n",
    "              'tweets_#patriots.txt', 'tweets_#sb49.txt', 'tweets_#superbowl.txt']\n",
    "for file_name in file_names:\n",
    "    calc_statistics(file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 2\n",
    "\n",
    "\n",
    "plot_num_tweets_per_hour('tweets_#superbowl.txt', '#SuperBowl')\n",
    "plot_num_tweets_per_hour('tweets_#nfl.txt', '#NFL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 3\n",
    "\n",
    "\n",
    "file_names = ['tweets_#gohawks.txt', 'tweets_#gopatriots.txt', 'tweets_#nfl.txt',\n",
    "              'tweets_#patriots.txt', 'tweets_#sb49.txt', 'tweets_#superbowl.txt']\n",
    "\n",
    "for file_name in file_names:\n",
    "    # X_train & y\n",
    "    X = extract_five_features(flie_name)\n",
    "    X_train = X[:-1,:]  \n",
    "    y = X[1:,0]\n",
    "    # train a model\n",
    "    RegressionModel = statsmodel.OLS(y, X_train).fit()\n",
    "    y_pred = RegressionModel.predict()\n",
    "    # do the calculation\n",
    "    print('*'*50)\n",
    "    print('For ', file_name,':')\n",
    "    mse = metrics.mean_squared_error(y, y_pred)\n",
    "    print('MSE value: ',mse)\n",
    "    print('Summary report: ')\n",
    "    print(model.summary())\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 4\n",
    "\n",
    "\n",
    "file_names = ['tweets_#gohawks.txt', 'tweets_#gopatriots.txt', 'tweets_#nfl.txt',\n",
    "              'tweets_#patriots.txt', 'tweets_#sb49.txt', 'tweets_#superbowl.txt']\n",
    "\n",
    "for file_name in file_names:\n",
    "    # X_train & y\n",
    "    X = extract_more_features(flie_name)\n",
    "    X_train = X[:-1,:]  \n",
    "    y = X[1:,0]\n",
    "    # train a model\n",
    "    RegressionModel = statsmodel.OLS(y, X_train).fit()\n",
    "    y_pred = RegressionModel.predict()\n",
    "    # do the calculation\n",
    "    print('*'*50)\n",
    "    print('For ', file_name,':')\n",
    "    mse = metrics.mean_squared_error(y, y_pred)\n",
    "    print('MSE value: ',mse)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
